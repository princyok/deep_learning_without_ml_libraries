{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration using the Breast cancer Wisconsin data\n",
    "\n",
    "The Breast cancer Wisconsin dataset is a dataset that describe the characteristics of the cell nuclei for 569 breast lumps, and includes whether they are malignant or benign.\n",
    "\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "**This Jupyter notebook will put to the test the artificial neuron that was written from scratch without dependence on any ML libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import artificial_neuron as an\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"../datasets/breast-cancer-wisconsin-data/data.csv\", delimiter=\",\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the target (\"daignosis\" column) from nominal strings (\"M\" and \"B\") to numbers (0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"diagnosis\"]=preprocessing.LabelEncoder().fit([\"M\",\"B\"]).transform(data[\"diagnosis\"]) # M is 0, B is 1.\n",
    "\n",
    "data.drop(columns=\"id\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the pandas Dataframe to numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test sets, and also seperate into features (x) and target (y). Also ensure the shape of the input and output tensors are as expected. For features: num_features x batch_size. For target: 1 x batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = model_selection.train_test_split(data, train_size=0.8, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 31)\n",
      "(114, 31)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 455)\n",
      "(31, 114)\n"
     ]
    }
   ],
   "source": [
    "data_train=data_train.T\n",
    "data_test=data_test.T\n",
    "\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=data_train[1:, :]\n",
    "y_train=data_train[0, :].reshape(1,-1)\n",
    "\n",
    "x_test=data_test[1:, :]\n",
    "y_test=data_test[0, :].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just start with some randomly chosen hyperparameters:\n",
    "\n",
    "* number of iterations: 10\n",
    "\n",
    "* learning rate (step size): 0.00007\n",
    "\n",
    "* batch size: 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins...\n",
      "Training Complete!\n",
      "Caution: All the activations are null values.\n",
      "training accuracy:  None\n",
      "Caution: All the activations are null values.\n",
      "test accuracy:      None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neuron=an.Neuron(X=x_train, Y=y_train)\n",
    "neuron.train(num_iterations=10, learning_rate=7e-5, batch_size=256)\n",
    "\n",
    "print(\"training accuracy: \", neuron.evaluate(X=x_train, Y=y_train, metric=\"accuracy\"))\n",
    "print(\"test accuracy:     \", neuron.evaluate(X=x_test, Y=y_test, metric=\"accuracy\"), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan ... nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "print(neuron.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We likely ran into an overflow or underflow somewhere which led to the NaNs. We can try to avoid this by tweaking our hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins...\n",
      "Training Complete!\n",
      "training accuracy:  0.36043956043956044\n",
      "test accuracy:      0.42105263157894735\n",
      "\n",
      "Training begins...\n",
      "Training Complete!\n",
      "training accuracy:  0.7846153846153846\n",
      "test accuracy:      0.7894736842105263\n",
      "\n",
      "Training begins...\n",
      "Training Complete!\n",
      "training accuracy:  0.9142857142857143\n",
      "test accuracy:      0.9035087719298246\n",
      "\n",
      "Training begins...\n",
      "Training Complete!\n",
      "training accuracy:  0.9120879120879121\n",
      "test accuracy:      0.8859649122807017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vaious_iterations=[50, 100, 500, 1000]\n",
    "for n in vaious_iterations:\n",
    "    neuron=an.Neuron(X=x_train, Y=y_train)\n",
    "    neuron.train(num_iterations=n, learning_rate=7e-5, batch_size=32)\n",
    "\n",
    "    print(\"training accuracy: \", neuron.evaluate(X=x_train, Y=y_train, metric=\"accuracy\"))\n",
    "    print(\"test accuracy:     \", neuron.evaluate(X=x_test, Y=y_test, metric=\"accuracy\"), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start seeing the training accuracy outpace the test accuracy by the time we are reaching 1000 iterations, so we stop there as that is possibly a sign that we are begining to overfit.\n",
    "\n",
    "**We have 90% test accuracy after 500 iterations.**\n",
    "\n",
    "We can play around with the other hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins...\n",
      "Training Complete!\n",
      "Caution: All the activations are null values.\n",
      "training accuracy:  None\n",
      "Caution: All the activations are null values.\n",
      "test accuracy:      None\n",
      "\n",
      "Training begins...\n",
      "Training Complete!\n",
      "Caution: All the activations are null values.\n",
      "training accuracy:  None\n",
      "Caution: All the activations are null values.\n",
      "test accuracy:      None\n",
      "\n",
      "Training begins...\n",
      "Training Complete!\n",
      "training accuracy:  0.9098901098901099\n",
      "test accuracy:      0.8859649122807017\n",
      "\n",
      "Training begins...\n",
      "Training Complete!\n",
      "training accuracy:  0.6725274725274726\n",
      "test accuracy:      0.6929824561403509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates=[7e-3,7e-4,7e-5,7e-6]\n",
    "for lr in learning_rates:    \n",
    "    neuron=an.Neuron(X=x_train, Y=y_train)\n",
    "    neuron.train(num_iterations=700, learning_rate=lr, batch_size=32)\n",
    "\n",
    "    print(\"training accuracy: \", neuron.evaluate(X=x_train, Y=y_train, metric=\"accuracy\"))\n",
    "    print(\"test accuracy:     \", neuron.evaluate(X=x_test, Y=y_test, metric=\"accuracy\"), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do same for batch. I will show how batch size with relatively high learning rate can also cause an overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins...\n",
      "Training Complete!\n",
      "training accuracy:  0.9076923076923077\n",
      "test accuracy:      0.8859649122807017\n",
      "[[0.98915491 0.11201739 0.10422711 ... 0.8189739  0.36198044 0.62945661]]\n",
      "\n",
      "Training begins...\n",
      "Training Complete!\n",
      "training accuracy:  0.9120879120879121\n",
      "test accuracy:      0.8859649122807017\n",
      "[[0.98987214 0.11257582 0.10552775 ... 0.82780702 0.365114   0.64058033]]\n",
      "\n",
      "Training begins...\n",
      "Training Complete!\n",
      "Caution: All the activations are null values.\n",
      "training accuracy:  None\n",
      "Caution: All the activations are null values.\n",
      "test accuracy:      None\n",
      "[[nan nan nan ... nan nan nan]]\n",
      "\n",
      "Training begins...\n",
      "Training Complete!\n",
      "Caution: All the activations are null values.\n",
      "training accuracy:  None\n",
      "Caution: All the activations are null values.\n",
      "test accuracy:      None\n",
      "[[nan nan nan ... nan nan nan]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# truncate printout of np array much earlier.\n",
    "np.set_printoptions(threshold=10)\n",
    "\n",
    "batch_sizes=[80, 81,82,83]\n",
    "for b in batch_sizes:\n",
    "    neuron=an.Neuron(X=x_train, Y=y_train)\n",
    "    neuron.train(num_iterations=500, learning_rate=7e-5, batch_size=b)\n",
    "    \n",
    "    print(\"training accuracy: \", neuron.evaluate(X=x_train, Y=y_train, metric=\"accuracy\"))\n",
    "    print(\"test accuracy:     \", neuron.evaluate(X=x_test, Y=y_test, metric=\"accuracy\"))\n",
    "    print(neuron.a, end=\"\\n\\n\")\n",
    "\n",
    "# resetting to the default.\n",
    "np.set_printoptions(threshold=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreasing the learning rate helps out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins...\n",
      "Training Complete!\n",
      "training accuracy:  0.8505494505494505\n",
      "test accuracy:      0.8771929824561403\n",
      "[[0.79281593 0.43818    0.37552943 ... 0.50387101 0.57332357 0.50667138]]\n",
      "\n",
      "Training begins...\n",
      "Training Complete!\n",
      "training accuracy:  0.843956043956044\n",
      "test accuracy:      0.8771929824561403\n",
      "[[0.79717373 0.43835257 0.37617978 ... 0.50892494 0.57455212 0.51037514]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# truncate printout of np array much earlier.\n",
    "np.set_printoptions(threshold=10)\n",
    "\n",
    "batch_sizes=[81,82]\n",
    "for b in batch_sizes:\n",
    "    neuron=an.Neuron(X=x_train, Y=y_train)\n",
    "    neuron.train(num_iterations=500, learning_rate=7e-6, batch_size=b)\n",
    "    \n",
    "    print(\"training accuracy: \", neuron.evaluate(X=x_train, Y=y_train, metric=\"accuracy\"))\n",
    "    print(\"test accuracy:     \", neuron.evaluate(X=x_test, Y=y_test, metric=\"accuracy\"))\n",
    "    print(neuron.a, end=\"\\n\\n\")\n",
    "\n",
    "# resetting to the default.\n",
    "np.set_printoptions(threshold=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
